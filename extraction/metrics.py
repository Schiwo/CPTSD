import pandas as pd
import argparse

from utils import (
    extract_split_and_deduplicate_symptoms,
    compute_section_jaccard,
    calculate_num_set,
    calculate_and_average_metrics,
    extract_sections,
    tokenize_numbering,
    mid_token_calc,
    mid_token_dist_calc,
)


def compute_metrics_zeroshot(gpt_result_filename):

    # extract ground-truth symptoms and estimated symptoms
    gpt_result = pd.read_excel(f"{gpt_result_filename}.xlsx")
    extract_symp1 = extract_split_and_deduplicate_symptoms(
        gpt_result, "Ground-truth label", "Symptom"
    )
    extract_symp2 = extract_split_and_deduplicate_symptoms(
        extract_symp1, "Estimation", "Estimated Symptom"
    )
    compute_metrics(extract_symp2)


def compute_metrics(extract_symp2):

    # calcuate metrics used for multi-label classification in estimating symptoms
    num_set_extract_symp2 = calculate_num_set(extract_symp2)
    calculate_and_average_metrics(num_set_extract_symp2, zeroshot_metric_symp)

    # extract ground-truth sections and estimated sections
    extract_sec = extract_sections(gpt_result)

    # compute Jaccard Index for section prediction
    extract_sec = compute_section_jaccard(extract_sec)
    mean_jaccard = extract_sec["Jaccard Index"].mean()
    print(f"Mean Jaccard Index between sections: {mean_jaccard:.3f}")

    # save updated file with Jaccard column
    extract_sec.to_excel(f"{gpt_result_filename}_with_jaccard.xlsx", index=False)

    # tokenize the text of ground-truth sections and estimated sections and number tokens of the text
    tokenize_numbering(extract_sec, token_num_sec)

    # calculate the mid-token of the ground-truth sections and estimated sections
    mid_token_calc(token_num_sec, mid_token_calc_sec)

    # calculate the recall mid-token distance
    mid_token_dist_calc(mid_token_calc_sec, zeroshot_midtoken)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Estimate Symptom and Section with Zero-shot Inference"
    )
    parser.add_argument(
        "--result", help="Filename of the output generated by GPT", required=True
    )

    args = parser.parse_args()
    compute_metrics(args.result)
