import pandas as pd
import argparse

from utils import (
    extract_split_and_deduplicate_symptoms,
    compute_section_jaccard,
    calculate_num_set,
    calculate_and_average_metrics,
    extract_sections,
    tokenize_numbering,
    mid_token_calc,
    mid_token_dist_calc,
    extract_symp_from_df_label,
    extract_symp_from_df_rag,
    extract_symp_from_df_icl,
)


def compute_metrics_zeroshot(gpt_result_filename):

    # extract ground-truth symptoms and estimated symptoms
    gpt_result = pd.read_excel(gpt_result_filename)
    extract_symp1 = extract_split_and_deduplicate_symptoms(
        gpt_result, "Ground-truth label", "Symptom"
    )
    extract_symp2 = extract_split_and_deduplicate_symptoms(
        extract_symp1, "Estimation", "Estimated Symptom"
    )
    compute_metrics(gpt_result, extract_symp2, gpt_result_filename)


def compute_metrics_rag(gpt_result_filename):

    # extract ground-truth symptoms
    gpt_result = pd.read_excel(f"{gpt_result_filename}.xlsx")
    extract_symp1 = extract_symp_from_df_label(
        gpt_result, "Ground-truth label", "Symptom"
    )

    # extract estimated symptoms
    extract_symp2 = extract_symp_from_df_rag(
        extract_symp1, "Estimation", "Estimated Symptom"
    )
    compute_metrics(gpt_result, extract_symp2, gpt_result_filename)


def compute_metrics_icl(gpt_result_filename):

    # extract ground-truth symptoms
    gpt_result = pd.read_excel(f"{gpt_result_filename}.xlsx")
    extract_symp1 = extract_symp_from_df_label(
        gpt_result, "Ground-truth label", "Symptom"
    )

    # extract estimated symptoms
    extract_symp2 = extract_symp_from_df_icl(
        extract_symp1, "Estimation", "Estimated Symptom"
    )
    compute_metrics(gpt_result, extract_symp2, gpt_result_filename)


def compute_metrics(gpt_result, extract_symp2, gpt_result_filename):

    # calculate metrics used for multi-label classification in estimating symptoms
    num_set_extract_symp2 = calculate_num_set(extract_symp2)
    calculate_and_average_metrics(
        num_set_extract_symp2, f"{gpt_result_filename[:-5]}_avg_metrics.xlsx"
    )

    # extract ground-truth sections and estimated sections
    extract_sec = extract_sections(gpt_result)

    # compute Jaccard Index for section prediction
    jaccard = compute_section_jaccard(extract_sec)

    # tokenize the text of ground-truth sections and estimated sections and number tokens of the text
    token_num_sec = tokenize_numbering(jaccard)

    # calculate the mid-token of the ground-truth sections and estimated sections
    mid_token_calc_sec = mid_token_calc(token_num_sec)

    # calculate the recall mid-token distance
    midtoken = mid_token_dist_calc(mid_token_calc_sec)

    midtoken.to_excel(f"{gpt_result_filename[:-5]}_with_metrics.xlsx", index=False)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Estimate Symptom and Section with Zero-shot Inference"
    )
    parser.add_argument(
        "--result", help="Filename of the output generated by GPT", required=True
    )

    args = parser.parse_args()
    compute_metrics_zeroshot(args.result)
